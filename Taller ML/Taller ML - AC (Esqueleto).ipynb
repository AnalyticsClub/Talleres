{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Machine Learning"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "El machine learning, conocido en español como aprendizaje automático o aprendizaje de máquina, nació como una idea ambiciosa de la IA en la década de los 60. Para ser más exactos, fue una subdisciplina de la IA, producto de las ciencias de la computación y las neurociencias.\n",
    "\n",
    "Lo que esta rama pretendía estudiar era el reconocimiento de patrones (en los procesos de ingeniería, matemáticas, computación, etc.) y el aprendizaje por parte de las computadoras. En los albores de la IA, los investigadores estaban ávidos por encontrar una forma en la cual las computadoras pudieran aprender únicamente basándose en datos."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div>\n",
    "<img src=\"ML.jpg\", width=\"350\"/>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Sucedió con el paso de los años que el machine learning comenzó a enfocarse en diferentes asuntos, tales como el razonamiento probabilístico, investigación basada en la estadística, recuperación de información, y continuó profundizando cada vez más en el reconocimiento de patrones (todos estos asuntos aplicados a procesos de ingeniería, matemáticas, computación y otros campos relacionados con objetos físicos o abstractos).\n",
    "\n",
    "Esto ocasionó que en los 90 se separara de la IA para convertirse en una disciplina por sí sola, aunque muchos puristas aún la consideran como parte de la IA. Ahora, el principal objetivo del machine learning es abordar y resolver problemas prácticos en donde se aplique cualquiera de las disciplinas numéricas antes mencionadas. (Adext AI, 2021)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Machine Learning en Pyton"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "La libreria tradicional para hacer ML en Python se llama Scikit-Learn, la cual tiene implementaciones de los modelos clásicos para atacar problemas de regresión, clasificación, clustering, preprocesamiento, selección de modelos y reducción de dimensionalidad. Como veremos más adelante, es una librería muy versatil, eficiente y sencilla de implementar"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div>\n",
    "<img src=\"Scikit.png\", width=\"950\"/>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Modelos de Aprendizaje"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Cuando hablamos de ML existen dos tipos de problemas a los cuales ns podemos estar enfrentando:\n",
    "* **Aprendizaje Supervisado**: Es el tipo de problemas donde tenemos una variable que queremos predecir ($Y$) y un grupo de variable para predecirla ($X$). \n",
    "* **Aprendizaje No Supervisado**: Es el tipo de problemas donde no tenemos una variable para predecir, unicamente tenemos el conjunto de variables $X$ y buscamos determinar si existe algun tipo de patron o asociacion entre ellas."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div>\n",
    "<img src=\"Sup.jpg\" width=\"850\"/>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## El Dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Antes de entrar a los modelos revisemos el dataset con el que vamos a trabajar. Los datos hacen referencia a clietes de un banco en Europa. Dentro del dataset hay clientes que han abandonado el banco y aquellos que no, nuestra mision es encontrar los determinantes que hacen que un cliente abandone el banco."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Aprendizaje Supervisado"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Existen varios modelos para atacar problemas de aprendizaje supervisado. En este taller veremos muy por encima los mas utlizados:\n",
    "* Regresión\n",
    "* Arboles\n",
    "* Random Forest\n",
    "* Support Vector Machine"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Regresión Lineal y Lógistica"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<tr>\n",
    "<td> <img src=\"RL.PNG\" alt=\"Drawing\" style=\"width: 450px;\"/> </td>\n",
    "<td> <img src=\"LR.PNG\" alt=\"Drawing\" style=\"width: 450px;\"/> </td>\n",
    "</tr>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Los modelos de regresión buscan modelar la relación que existe entre una variable independiente $Y$ y unas variables explicativas $X$ de manera lineal, de la forma:\n",
    "\n",
    "$$ Y = \\beta_0+\\beta_1X_1+\\cdots+\\beta_kX_k + \\epsilon$$\n",
    "\n",
    "Si la variable $Y$ es continua, tratamos con una **regresión tradicional**, mientras que si es binaria tratamos con una **regresión logística**."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Documentacion en Scikit: <a href=\"https://scikit-learn.org/stable/modules/generated/sklearn.linear_model.LogisticRegression.html?highlight=logistic#sklearn.linear_model.LogisticRegression\">Logistic Regression</a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "En python:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Árboles de Clasificación"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* El enfoque classification and regression tree (CART) fue desarrollado por Breiman et al. (1984).\n",
    "* Principalmente usados en problemas de clasificación (Pero tambien pueden utilizarse para regresión)\n",
    "* Las variables de entrada y salida pueden ser categóricas o continuas.\n",
    "* Divide el espacio de predictores (variables independientes) en regiones distintas y no sobrepuestas."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div>\n",
    "<img src=\"CART.PNG\" width=\"750\"/>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Documentacion en Scikit: <a href=\"https://scikit-learn.org/stable/modules/generated/sklearn.tree.DecisionTreeClassifier.html?highlight=decision%20tree#sklearn.tree.DecisionTreeClassifier\">Decision Tree Classifiers</a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "En python:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.tree import DecisionTreeClassifier\n",
    "clf = DecisionTreeClassifier()\n",
    "clf.fit(X, Y)\n",
    "y_pred = clf.predict(X)\n",
    "y_pred_proba = clf.predict_proba(X)[:,1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import roc_auc_score, accuracy_score, fbeta_score, r2_score, mean_squared_error\n",
    "print('La precisión del modelo es:', '{:.2f}'.format(accuracy_score(Y, y_pred)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Random Forest"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Random Forest se considera como la “panacea” en todos los problemas de ciencia de datos.\n",
    "* Util para regresión y clasificación.\n",
    "* Consiste en un grupo de modelos “débiles”, se combinan en un modelo robusto.\n",
    "* Se generan múltiples árboles (a diferencia de CART). Cada árbol da una classificación (vota por una clase) y el resultado es la clase con mayor número de votos en todo el bosque (forest).\n",
    "* Para regresión, se toma el promedio de las salidas (predicciones) de todos los árboles."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div>\n",
    "<img src=\"RF.png\" width=\"750\"/>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Documentacion en Scikit: <a href=\"https://scikit-learn.org/stable/modules/generated/sklearn.ensemble.RandomForestClassifier.html?highlight=randomforest#sklearn.ensemble.RandomForestClassifier\">Random Forest Classifiers</a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "En python:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Support Vector Machine"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "El objectivo es encontrar un hiperplano en un espacio N dimensional (N — el número de entidades) que clasifica claramente los puntos de datos. Para separar las dos clases de puntos de datos, hay muchos hiperplanos posibles que podrían ser elegidos. Nuestro objetivo es encontrar un plano que tenga el margen máximo, es decir, la distancia máxima entre los puntos de datos de ambas clases. Maximizar la distancia de margen proporciona cierto refuerzo para que los puntos de datos futuros se puedan clasificar con más confianza."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div>\n",
    "<img src=\"SVM.png\" width=\"750\"/>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Documentacion en Scikit: <a href=\"https://scikit-learn.org/stable/modules/generated/sklearn.svm.SVC.html#sklearn.svm.SVC\">Support Vector Classifiers</a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "En python:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Overfitting y Underfitting"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "El entrenar un modelo con todos los datos que tenemos a nuestra dispocición nos puede jugar una mala pasada. \n",
    "\n",
    "Ya que la finalidad del modelo que contruyamos es ser usado con nuevos datos, del mundo real, normalmente dividimos nuestra base en dos subconjuntos: datos de entrenamiento y datos de prueba (y a veces a tres: entrenar, validar y probar), y ajustar nuestro modelo en los datos del train, con el fin de hacer predicciones sobre los datos de prueba. Cuando hacemos eso, una de dos cosas puede suceder: \"overfitting\" (sobreajuste) o \"underfitting\" (subajuste)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div>\n",
    "<img src=\"ofuf.png\" width=\"750\"/>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "El **Overfitting** ocurre cuando nuestro modelo se ajusta demasiado bien a los datos. En otras palabras en ves de aprender de los datos, los memorizo. Esto hace que sobre los datos que entrenamos tengamos errores muy bajos y precisiones muy altas, pero con cualquier dato nuevo (no visto durante el entrenamiento) el modelo no sabra que hacer.  \n",
    "\n",
    "Esto suele ocurrir cuando el modelo es demasiado complejo (es decir, demasiadas características/variables en comparación con el número de observaciones). Este modelo será muy preciso en los datos de entrenamiento, pero probablemente no será muy preciso en datos no entrenados o nuevos. Esto se debe a que este modelo no está generalizado (o no como generalizado), lo que significa que puede generalizar los resultados y no puede hacer ninguna inferencia sobre otros datos, que es, en última instancia, lo que está intentando hacer. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Por otra parte el **Underfitting** ocurre cuando el modelo no se ajusta bien ni siquiera a los datos de entrenamiento y por esto deja de lado las tendencias presentes en los datos. También significa que el modelo no se puede generalizar a nuevos datos. \n",
    "\n",
    "De manera contraria al **Overfitting**, esto suele ser el resultado de un modelo muy simple (no hay suficientes predictores / variables independientes) (Towards Data Science, 2021)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train - Test Split"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Con el fin de minimizar los problemas mencionados anteriormente, la base de datos se separa en normalmente en dos: Datos de trin, con los que se entrena el modelo y los dato de Test con los que se prueba o mide el modelo construido. Normalmente se hace una separación de 80 - 20 o 70 - 30, siendo el primer número el porcentaje de los datos que se usa para entrenar y el segundo número el porcentaje de los datos que se usa para probar."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div>\n",
    "<img src=\"train-test.png\" width=\"750\"/>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Validación Cruzada"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Junto con la separación de datos, podemos hacer uso de la validación cruzada para garantizar o maximizar el potencial de generalización que tendra nuestro modelo y de la misma manera, su utilidad. La validación cruzada es muy similar a la división de train/test, pero se aplica a más subconjuntos."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div>\n",
    "<img src=\"kfcv.png\" width=\"750\"/>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "La idea la este tipo de validación es tomar el conjunto de datos de entrenamiento y separarlo en k grupos del mismo tamaño. Utilizamos k-1 grupos para entrenar el modelo y utilizamos el ultimo para test. Repetimos el procedimiento de manera que todos los subcojuntos sean utilizados una vez como test. De esta manera todos los conjuntos son usado al menos una vez como parte del entrenamiento y como parte del test, lo que previene que el modelo se memorice los datos, pues estos siempren van cambiando y para ser considerado bueno debe tener buen desempeño sobre todos los subconjuntos. Para finalizar, promediamos los resultados de cada iteración y esta sera una medida de la generalización del modelo. \n",
    "\n",
    "Al tener nuestro modelo entrenado por validación cruzada procedemos a probarlo contra los datos que nunca ha visto, el conjunto original de test.\n",
    "\n",
    "La validación cruzada será tambien nuestra herramienta para seleccionar el mejor conjunto de parámetros para nuestro modelo."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Calibración de Hiperparámetros"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Cada uno de los algoritmos de aprendizaje depende de una serie de hiperparámetros que determinan la menra en como se coporta y responde el algoritmo. Seleccionando el conjunto \"optimo\"de parámetros para nuestro caso particular, podemosmaximizar el desempeño del algoritmo utilizado. Es importante tener en cuenta que cada algoritmo posee una serie diferente de parametros con los que ponemos jugar."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div>\n",
    "<img src=\"tuning.png\" width=\"550\"/>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "La calibración de los hiperparámetros podemos hacerla mediante *GridSearch* o *RandomSearch*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Medidas de calidad del Modelo"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Nuestro fin es construir el mejor modelo para la situación específica en la que trabajamos pero, como sabemos si un modelo es el \"mejor\"? aun mas, como sabemos si un modelo es bueno. Para los modelos que construimos anteriormente calculamos la precisión de las predicciones, pero existen muchas mas medidas que pueden ser mejores y nos pueden dar mas información.\n",
    "\n",
    "Para modelos de clasificación binarios, la base de todas estas medidas de calidad se halla en la **matriz de confusión**: \n",
    "* Una matriz de confusión es una herramienta que permite la visualización del desempeño de un algoritmo que se emplea en aprendizaje supervisado. Cada columna de la matriz representa el número de predicciones de cada clase, mientras que cada fila representa a las instancias en la clase real. Uno de los beneficios de las matrices de confusión es que facilitan ver si el sistema está confundiendo dos clases."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div>\n",
    "<img src=\"conf.jpg\" width=\"700\"/>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Las métricas mas comunes de la matriz son:\n",
    "* **La precisión**: Mide el porcentaje de aciertos del modelo.\n",
    "* **La sensibilidad**: Mide la capacidad del modelo de predecir la clase \"Positiva\" (los 1's).\n",
    "* **La especificidad**: Mide la capacidad del modelo de predecir la clase \"Negativa\" (los 0's)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Otra medida muy popular, que puede considerrse mejor que las anteriores es el area bajo la curva ROC **(AUC)**:\n",
    "\n",
    "* \"La curva Característica del operador receptor (ROC) es una métrica de evaluación para problemas de clasificación binaria. Es una curva de probabilidad que traza el TPR contra el FPR en varios valores de umbral y esencialmente separa la «señal» del «ruido».El Área bajo la curva (AUC) es la medida de la capacidad de un clasificador para distinguir entre clases y se utiliza como resumen de la curva ROC.\" (Analytics Vidhya, 2020)\n",
    "\n",
    "* Cuando el área bajo la curva es igual a 1, el clasificador es capaz de distinguir perfectamente entre todos los puntos de Positivos y Negativos correctamente. Sin embargo, si el AUC hubiera sido 0, entonces el clasificador estaría prediciendo todos los negativos como positivos, y todos los positivos como negativos.\n",
    "\n",
    "* Cuando 0.5 < AUC < 1, existe una alta probabilidad de que el clasificador pueda distinguir los valores de clase positivos de los valores de clase negativos. Esto es así porque el clasificador es capaz de detectar más números de verdaderos positivos y verdaderos negativos que falsos negativos y falsos positivos.\n",
    "\n",
    "* Cuando AUC = 0.5, el clasificador no puede distinguir entre puntos de clase positivos y negativos. Lo que significa que el clasificador predice clase aleatoria o clase constante para todos los puntos de datos.\n",
    "\n",
    "* Por lo tanto, cuanto mayor sea el valor AUC para un clasificador, mejor será su capacidad para distinguir entre clases positivas y negativas.\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div>\n",
    "<img src=\"roc.png\" width=\"400\"/>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Mas información de la curva ROC: <a href=\"https://www.analyticsvidhya.com/blog/2020/06/auc-roc-curve-machine-learning/\">AUC</a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ahora que ya conocemos mas acerca del proceso, apliquemos todo esto a los modelos anteriores:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Modelado (Como debe ser!)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Tomemos la regresion logistica como ejemplo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Podemos ver información mas detallada con el comando *classification_report*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Finalmente podemos ver el efecto o relevancia de cada variable en la clasificación final. Para el caso de la Regresión Logística, esto lo encontramos en los coeficientes de las variables."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ciertamente podemos repetir todo este procedimiento para cada uno de nuestros modelos, uno a uno, pero mejor hagamos uso de python para consensar nuestros analisis y resultados en un solo lugar, de manera que nuestro código se vea organizado y optimizado y de la misma manera nos sea muy facil comparar modelos y tomar una decisión"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Putting it all together"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Primero hagamos la separación entre train y test."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ahora, generemos un pipeline y una grilla para cada uno de los modelo que queremos analizar."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ahora construyamos una lista y diccionario de las grillas, para que sea mas facil su recorrido."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Listo, ahora podemos construir un recorrido para correr nuestros modelos uno despues de otro y compararlos."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
